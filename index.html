<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" type="text/css" href="styles.css">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Poppins" />
    <title>Spreadle</title>
  
</head>
<body>
    <header class="sticky">
        <a href="#" class="logo">Spread<span>le</span>
         
            <ul class="navigation">
                <li><a></a></li>
                <li><a href="#banner">Home</a></li>
                <li><a href="#about">About</a></li>
                <li><a href="#tech">Tech</a></li>
                <li><a href="#banner"><img id="themeToggle" src="sun.png" alt="Light Mode Icon" width="25"></a></li>
            </ul>
            <div class="menuToggle" onclick="toggleMenu();"></div>
    </header>
   <section class="banner" id="banner">
    <div class="content">
        <h2>Google Gemini Will Be Multimodal</h2><br>
        <p>Pichai stated that Gemini combines the strengths of DeepMind’s AlphaGo system, known for mastering the complex game Go, with extensive language modeling capabilities.</p><br>
        <p>He said it is designed from the ground up to be multimodal, integrating text, images, and other data types. This could allow for more natural conversational abilities.</p><br>
        <p>Pichai also hinted at future capabilities like memory and planning that could enable tasks requiring reasoning.</p><br>
        <h2>Gemini Can Use Tools And APIs</h2><br>
        <p>In an update to his professional bio over the summer, Google Chief Scientist Jeffrey Dean said Gemini is one of the “next-generation multimodal models” he is co-leading.</p><br>
        <a href="#" class="button">Search</a>
    </div>

   </section>
   <section class="about" id="about">
    <div class="title">
        <h2>About Us</h2>
    </div>
   </section>

   <script src ="script.js"></script>
</body>
</html>
